# -*- coding: utf-8 -*-
"""add 'seasonal' to time_resolution enum

Revision ID: 614911daf883
Revises: 7847aa3c1b39
Create Date: 2017-07-17 17:00:43.066818

"""
from warnings import warn

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '614911daf883'
down_revision = '7847aa3c1b39'
branch_labels = None
depends_on = None


def get_dialect():
    connection = op.get_bind()
    dialect = connection.dialect.name
    return dialect


# This is a *highly* customized migration script, barely related to the
# autogenerated script at all. Two reasons:
#
# 1) There are a lot of differences between the (test, and presumably prod)
#    database as it is now and the SQLAlchemy declaration. We ditch almost all
#    those differences because we are frightened little creatures who don't
#    want to wake monsters.
# 2) Enum type. See below.
#
# Migration of an Enum type must be done differently depending on the database
# type. ~sigh~
#
# For SQLite, we must use "batch mode" to
# do most table alterations, including the one that changes the Enum type
# for time_resolution. See http://alembic.zzzcomputing.com/en/latest/batch.html
#
# That documentation says
#   On other backends, we'd see the usual ALTER statements done as though
#   there were no batch directive - the batch context by default only does
#   the “move and copy” process if SQLite is in use, and if there are migration
#   directives other than Operations.add_column() present, which is the one
#   kind of column-level ALTER statement that SQLite supports.
#
# But unfortunately Enum type is a special case, and batch mode only works for
# SQLite.
#
# For PostgreSQL, we must use a different technique, as below.
#
# TESTING:
#
# These migrations have been tested on a SQLite test database and on
# a full copy of the production database. Both upgrade and downgrade work
# on both databases.

table_name = 'time_sets'
column_name = 'time_resolution'
type_name = 'timescale'

old_options = (
    '1-minute', '2-minute', '5-minute', '15-minute', '30-minute',
    '1-hourly', '3-hourly', '6-hourly', '12-hourly', 'daily',
    'monthly', 'yearly', 'other', 'irregular',
)
new_options = (
    '1-minute', '2-minute', '5-minute', '15-minute', '30-minute',
    '1-hourly', '3-hourly', '6-hourly', '12-hourly', 'daily',
    'monthly', 'seasonal', 'yearly', 'other', 'irregular',
)


def alter_column(curr_options, dest_options):
    """
    Alter columns, which in SQLite alters the check constraint. Yay.
    See http://alembic.zzzcomputing.com/en/latest/batch.html

    :param curr_options: tuple of options (members) in the current enum type
    :param dest_options: tuple of options (members) in the destination enum type
    :return: None
    """
    old_type = sa.Enum(*curr_options, name=type_name)
    new_type = sa.Enum(*dest_options, name=type_name)
    with op.batch_alter_table(table_name) as batch_op:
        batch_op.alter_column(
            'time_resolution', type_=new_type, existing_type=old_type)


def swap_and_drop(curr_options, dest_options):
    """
    Create a temporary enum type with the destination options in it,
    swap it for the current enum type with the current options in it,
    then rename the temporary and drop the temporary and old enum types.
    This works for PostgreSQL.

    Adapted from https://stackoverflow.com/questions/14845203/altering-an-enum-field-using-alembic

    :param curr_options: tuple of options (members) in the current enum type
    :param dest_options: tuple of options (members) in the destination enum type
    :return: None
    """
    connection = op.get_bind()
    tmp_type_name = '_{}'.format(type_name)
    alter_args = dict(
        table_name=table_name,
        column_name=column_name,
        type_name=type_name,
        tmp_type_name=tmp_type_name,
    )
    old_type = sa.Enum(*curr_options, name=type_name)
    new_type = sa.Enum(*dest_options, name=type_name)
    tmp_type = sa.Enum(*dest_options, name=tmp_type_name)

    # Create a temporary enum type, convert to it and drop the old enum type
    tmp_type.create(connection, checkfirst=False)
    op.execute(sa.text('''
        ALTER TABLE {table_name}
        ALTER COLUMN {column_name}
        TYPE {tmp_type_name}
        USING {column_name}::text::{tmp_type_name}
    '''.format(**alter_args)))
    old_type.drop(connection, checkfirst=False)

    # Create and convert to the new enum type
    new_type.create(connection, checkfirst=False)
    op.execute(sa.text('''
        ALTER TABLE {table_name}
        ALTER COLUMN {column_name}
        TYPE {type_name}
        USING {column_name}::text::{type_name}
    '''.format(**alter_args)))

    # Drop the temporary enum type
    tmp_type.drop(connection, checkfirst=False)


def upgrade():
    dialect = get_dialect()
    if dialect == 'sqlite':
        alter_column(old_options, new_options)
    else:
        if dialect != 'postgresql':
            warn('This migration is not tested for dialect {}'
                 .format(dialect))
        swap_and_drop(old_options, new_options)


def downgrade():
    dialect = get_dialect()

    # Migrate the data. This is dialect-independent.
    metadata = sa.MetaData()
    time_sets = sa.Table(
        table_name,
        metadata,
        sa.Column(column_name, sa.Enum(*new_options, name=type_name)),
    )
    op.execute(
        time_sets.update()
            .where(time_sets.c.time_resolution == 'seasonal')
            .values(time_resolution='other')
    )

    # Migrate the schema (enum type)
    if dialect == 'sqlite':
        alter_column(new_options, old_options)
    else:
        if dialect != 'postgresql':
            warn('This migration is not tested for dialect {}'
                 .format(dialect))
        swap_and_drop(new_options, old_options)
